{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T12:56:14.729891Z",
     "start_time": "2024-11-24T12:55:59.519393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.chat_models import ChatLlamaCpp\n",
    "%pip install flash_attn\n"
   ],
   "id": "d8b18d3ef00e60a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flash_attnNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Getting requirements to build wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [20 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Iheb\\Desktop\\projects\\finetune_gemma\\env\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "      main()\n",
      "    File \"C:\\Users\\Iheb\\Desktop\\projects\\finetune_gemma\\env\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Iheb\\Desktop\\projects\\finetune_gemma\\env\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "      return hook(config_settings)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Iheb\\AppData\\Local\\Temp\\pip-build-env-viflueas\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 334, in get_requires_for_build_wheel\n",
      "      return self._get_build_requires(config_settings, requirements=[])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Iheb\\AppData\\Local\\Temp\\pip-build-env-viflueas\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 304, in _get_build_requires\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\Iheb\\AppData\\Local\\Temp\\pip-build-env-viflueas\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 522, in run_setup\n",
      "      super().run_setup(setup_script=setup_script)\n",
      "    File \"C:\\Users\\Iheb\\AppData\\Local\\Temp\\pip-build-env-viflueas\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 320, in run_setup\n",
      "      exec(code, locals())\n",
      "    File \"<string>\", line 21, in <module>\n",
      "  ModuleNotFoundError: No module named 'torch'\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "Getting requirements to build wheel did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached flash_attn-2.7.0.post2.tar.gz (2.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T15:23:49.301097Z",
     "start_time": "2024-11-24T15:23:49.262081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch \n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "23fbbc9a6c5d88a2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T14:02:29.085513Z",
     "start_time": "2024-12-14T14:02:10.010585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test.py\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "device=torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "img_path=r\"C:\\Users\\Iheb\\Pictures\\Screenshots\\text before bin.png\"\n",
    "cache_dir = r\"C:\\Users\\Iheb\\.cache\\huggingface\\hub\\models--openbmb--MiniCPM-V-2_6-int4\\snapshots\\6f1555d8e2359cb18595da9f1864cb41631e0617\"\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('openbmb/MiniCPM-V-2_6-int4',      \n",
    "                                             local_files_only=True,\n",
    "                                             trust_remote_code=True,\n",
    "                                             attn_implementation=\"sdpa\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-V-2_6-int4',\n",
    "                                          local_files_only=True,\n",
    "                                          trust_remote_code=True)\n",
    "model=model.eval()\n",
    "\n"
   ],
   "id": "d429e9904119cf73",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46c044162f2544038332bf60a05e51c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T14:03:49.228382Z",
     "start_time": "2024-12-14T14:03:49.219687Z"
    }
   },
   "cell_type": "code",
   "source": "model.config",
   "id": "9dc89e3d8c6c532c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniCPMVConfig {\n",
       "  \"_name_or_path\": \"openbmb/MiniCPM-V-2_6-int4\",\n",
       "  \"architectures\": [\n",
       "    \"MiniCPMV\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"auto_map\": {\n",
       "    \"AutoConfig\": \"openbmb/MiniCPM-V-2_6-int4--configuration_minicpm.MiniCPMVConfig\",\n",
       "    \"AutoModel\": \"openbmb/MiniCPM-V-2_6-int4--modeling_minicpmv.MiniCPMV\",\n",
       "    \"AutoModelForCausalLM\": \"openbmb/MiniCPM-V-2_6-int4--modeling_minicpmv.MiniCPMV\"\n",
       "  },\n",
       "  \"batch_vision_input\": true,\n",
       "  \"bos_token_id\": 151643,\n",
       "  \"drop_vision_last_layer\": false,\n",
       "  \"eos_token_id\": 151645,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 3584,\n",
       "  \"image_size\": 448,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 18944,\n",
       "  \"max_position_embeddings\": 32768,\n",
       "  \"max_window_layers\": 28,\n",
       "  \"model_type\": \"minicpmv\",\n",
       "  \"num_attention_heads\": 28,\n",
       "  \"num_hidden_layers\": 28,\n",
       "  \"num_key_value_heads\": 4,\n",
       "  \"patch_size\": 14,\n",
       "  \"quantization_config\": {\n",
       "    \"_load_in_4bit\": true,\n",
       "    \"_load_in_8bit\": false,\n",
       "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
       "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
       "    \"bnb_4bit_quant_type\": \"nf4\",\n",
       "    \"bnb_4bit_use_double_quant\": true,\n",
       "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
       "    \"llm_int8_has_fp16_weight\": false,\n",
       "    \"llm_int8_skip_modules\": [\n",
       "      \"out_proj\",\n",
       "      \"kv_proj\",\n",
       "      \"lm_head\"\n",
       "    ],\n",
       "    \"llm_int8_threshold\": 6.0,\n",
       "    \"load_in_4bit\": true,\n",
       "    \"load_in_8bit\": false,\n",
       "    \"quant_method\": \"bitsandbytes\"\n",
       "  },\n",
       "  \"query_num\": 64,\n",
       "  \"rms_norm_eps\": 1e-06,\n",
       "  \"rope_theta\": 1000000.0,\n",
       "  \"slice_config\": {\n",
       "    \"max_slice_nums\": 9,\n",
       "    \"model_type\": \"minicpmv\"\n",
       "  },\n",
       "  \"slice_mode\": true,\n",
       "  \"sliding_window\": null,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.43.3\",\n",
       "  \"use_cache\": true,\n",
       "  \"use_image_id\": true,\n",
       "  \"use_sliding_window\": false,\n",
       "  \"version\": 2.6,\n",
       "  \"vision_batch_size\": 16,\n",
       "  \"vision_config\": {\n",
       "    \"hidden_size\": 1152,\n",
       "    \"image_size\": 980,\n",
       "    \"intermediate_size\": 4304,\n",
       "    \"model_type\": \"siglip_vision_model\",\n",
       "    \"num_attention_heads\": 16,\n",
       "    \"num_hidden_layers\": 27,\n",
       "    \"patch_size\": 14\n",
       "  },\n",
       "  \"vocab_size\": 151666\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T13:38:26.087793Z",
     "start_time": "2024-12-14T13:38:26.045831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img=Image.open(r\"C:\\Users\\Iheb\\Pictures\\Screenshots\\Screenshot 2024-11-26 140345.png\").convert(\"RGB\")\n",
    "invoice_prompt = (\"\"\"\n",
    "This image represent an invoice, your task is to retrieve information from this invoice in the format mentioned below /n\n",
    "\n",
    "///FORMAT///\n",
    "Account Number: {the account number}  \n",
    "Receiver Name: {to WHOM THIS INVOICE IS SENT}  \n",
    "Receiver Address: {the address of the customer}  \n",
    "Amount to be Paid: {the amount paid}  \n",
    "Period of the Invoice: {start period - end period}  \n",
    "\n",
    "//\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "job_requirements=\"\"\"\n",
    "Requirements: /n\n",
    "\n",
    "Master’s degree or higher in Data Science, Computer Science, Computer Engineering, Electrical Engineering, Robotics, Physics, Mathematics, or related fields.\n",
    "Deep understanding and experience with Image Theory, Deep Learning, Machine Learning, Python Programming, TensorFlow, or PyTorch.\n",
    "Strong experience in designing and implementing large-scale data processing, analysis, and exploration solutions.\n",
    "Proficiency in R, Python, advanced SQL skills, and a good understanding of data management principles.\n",
    "Experience with cloud technologies (Azure or GCP preferred) and deploying CI/CD pipelines.\n",
    "Knowledge of Git, PySpark, Data Bricks, and database management (SQL/PLSQL/Snowflake preferred).\n",
    "Excellent communication skills and the ability to work independently and collaborate across teams.\n",
    "2+ years of industry or academia experience in image processing, computer vision, or related fields.\"\"\"\n",
    "\n",
    "resume_prompt=(f\"\"\"\n",
    "     \"You are an AI recruiter tasked with selecting the best resume for a specific job opening. Carefully analyze the provided job description. Your goal is to evaluate the resume based on relevance, skills, experience, and alignment with the job.\n",
    "     ///NOTE: YOU ARE ONLY DEMANDED TO RETURN THE OUTPUT FORMAT ///\n",
    "\n",
    "///Job Description:///\n",
    "{job_requirements}\n",
    "\n",
    "\n",
    "\n",
    "///Evaluation Criteria:///\n",
    "\n",
    "Skill Match: Rate how well the candidate’s skills align with the required skills (the section mentioned above)./n\n",
    "Experience Relevance: Assess the relevance of the candidate's previous work experience to the job description./n\n",
    "Education Fit: Evaluate the candidate's educational background in relation to the job requirements./n\n",
    "Achievements: Identify and score notable achievements, certifications, or projects that demonstrate qualifications for this role./n\n",
    "Overall Fit: Provide an overall score and explanation of why this candidate is the best fit.\n",
    "Output Format:/n\n",
    "\n",
    "///Output Format:////n\n",
    "Generate the following output:\n",
    "\n",
    "Candidate Name: [Name]\n",
    "Skill Match Score: [0-10]\n",
    "Experience Relevance Score: [0-10]\n",
    "Education Fit Score: [0-10]\n",
    "Notable Achievements: [List key achievements and minimize them ]\n",
    "Overall Fit Score: [0-10]\n",
    "Explanation: [Summarize why this candidate is or isn't the best fit for the role.]\n",
    "\"\"\")\n"
   ],
   "id": "2b407a9c160c19d8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T13:38:34.300862Z",
     "start_time": "2024-12-14T13:38:34.297334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "comments=(\"I hate this application, adds keep popping up and does not allow me to navigate the site\",\"This application is slower than my grandma, you should fix this. I don't want to\")\n",
    "\n",
    "problem_template=(\"\"\"\n",
    "You are responsable for the customer satisfaction departement in the Entreprise and your job is to analyse the comments, highlight the problem and then suggest a solution for it./n/n\n",
    "\n",
    "////Comments///\n",
    "1. \"I have been using this app for a while now and I must say that it has been nothing but frustrating. The interface is confusing, the features are limited, and the customer support is practically nonexistent.\"/n\n",
    "2. \"I had high hopes for this app, but it has completely failed to meet my expectations. It's slow, unreliable, and constantly crashes. I've tried reaching out to their support team multiple times, but they never seem to respond in a timely manner.\" /n\n",
    "3. \"The concept of this app seems interesting, but its execution leaves much to be desired. The design is outdated, the functionality is lacking, and the overall user experience is just terrible.\"/n\n",
    "4. \"I'm really disappointed with how this app has turned out. It promised so much, but delivered very little. Its lack of features and poor performance make it almost unusable.\"/n\n",
    "5. \"I regret ever downloading this app. It's filled with bugs, glitches, and errors that make it nearly impossible to use. The developers should seriously consider revamping it or giving up on it altogether.\"/n\n",
    "\n",
    "///OUTPUT FORMAT:/n///\n",
    "Return a json like format highlighting briefly the problem encountered and the solution for every comment and keep it short.\n",
    " \n",
    "\"\"\")"
   ],
   "id": "8d460fe5b4753474",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T13:39:33.325294Z",
     "start_time": "2024-12-14T13:38:34.624634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "comments_template=\"\"\"Generate me 5 comments from dissatisfied customers using an application that you may specify\"\"\"\n",
    "\n",
    "msgs = [{'role': 'user', 'content': [problem_template, None]}]\n",
    "\n",
    "\n",
    "res = model.chat(\n",
    "    image=None,\n",
    "    msgs=msgs,\n",
    "    tokenizer=tokenizer,\n",
    "    sampling=True,\n",
    "    temperature=0.7,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "generated_text = \"\"\n",
    "for new_text in res:\n",
    "    generated_text += new_text\n",
    "    print(new_text, flush=True, end='')"
   ],
   "id": "62c6b297d07c0930",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Iheb\\Desktop\\projects\\finetune_gemma\\env\\Lib\\site-packages\\transformers\\models\\auto\\image_processing_auto.py:513: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Iheb\\Desktop\\projects\\finetune_gemma\\env\\Lib\\site-packages\\transformers\\models\\qwen2\\modeling_qwen2.py:521: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"comment1\": {\n",
      "    \"problem\": \"Confusing interface, limited features, and poor customer support.\",\n",
      "    \"solution\": \"Improve the app's user interface design, expand the feature set, and enhance customer support response times.\"\n",
      "  },\n",
      "  \"comment2\": {\n",
      "    \"problem\": \"Slowness, unreliability, crashes, and lack of timely support.\",\n",
      "    \"solution\": \"Optimize app performance, fix bugs, and ensure a faster response from the support team.\"\n",
      "  },\n",
      "  \"comment3\": {\n",
      "    \"problem\": \"Outdated design, lacking functionality, and terrible user experience.\",\n",
      "    \"solution\": \"Revamp the app's design, add new functionalities, and improve overall usability.\"\n",
      "  },\n",
      "  \"comment4\": {\n",
      "    \"problem\": \"Lack of features and poor performance making it almost unusable.\",\n",
      "    \"solution\": \"Add more features to the app and optimize its performance for better user experience.\"\n",
      "  },\n",
      "  \"comment5\": {\n",
      "    \"problem\": \"Filled with bugs, glitches, errors, and nearly impossible to use.\",\n",
      "    \"solution\": \"Fix existing bugs, improve stability, and consider a complete redesign or rebranding if necessary.\"\n",
      "  }\n",
      "}"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T21:12:51.497949Z",
     "start_time": "2024-11-27T21:09:42.698168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import \n",
    "lcd_img=Image.open(r\"C:\\Users\\Iheb\\Pictures\\Screenshots\\Screenshot 2024-11-27 215951.png\")\n",
    "hardware=(\"\"\"you are a hardware expert with 30+ years of experience and you encountered a specific problem here is the statement of the problem. You are to provide a solution for this problem\n",
    "\n",
    "//problem statement//:\n",
    "dans mon système si j'ai éliminé la pompe et les 4 injecteurs le système fonctionne correctement et il donne l'affichage correcte et détaillé. si j'ai installé la pompe et les 4 injecteurs il fonctionne correctement et afficher comme il faut et j'ai appuyé sur le bouton marche il affiche le système en cours... mais si le cycle est arrêté l'afficheur LCD affiche des symbole et des zéros sur l'ecriture, donc le défaut ou dans la partie programmation ou la partie de câblage sachant que j'ai alimenté le systéme par une boitier d'alimentation de l'ordinateur qui fournis 12V 10A max( alimenter par les 4 injecteurs et la pompe), 5V 25A max(alimenter par la module de 5 relais et l'afficheur LCD 20x4) et 3.3V 14A max (alimenter par la carte ESP 32) et pour la boitier donne une masse commune qui relier tous les systèmes avec les boutons aussi. donc est ce que c'est possible tu me donner ou le defaut ?\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "msgs = [{'role': 'user', 'content': [hardware, lcd_img]}]\n",
    "\n",
    "res = model.chat(\n",
    "    image=None,\n",
    "    msgs=msgs,\n",
    "    max_len=4096,\n",
    "    tokenizer=tokenizer,\n",
    "    sampling=True,\n",
    "    temperature=0.7,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "generated_text = \"\"\n",
    "for new_text in res:\n",
    "    generated_text += new_text\n",
    "    print(new_text, flush=True, end='')"
   ],
   "id": "a594a2d5e61b9283",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your problem appears to be related to the LCD display showing symbols and zeros instead of displaying data correctly when the system is stopped. Here are some possible solutions:\n",
      "\n",
      "1. **Check the Power Supply:**\n",
      "   Ensure that all power supplies (12V, 5V, 3.3V) are stable and within their respective maximum limits (10A, 25A, 14A). Voltage drops or instability can cause erratic behavior in the LCD display.\n",
      "\n",
      "2. **Verify Connections:**\n",
      "   Make sure all connections between the LCD display, ESP32 board, and other components are secure and properly made. Loose or incorrect connections can lead to display issues.\n",
      "\n",
      "3. **Reset the System:**\n",
      "   Sometimes a simple reset of the system can resolve display issues. Try resetting the ESP32 board by holding down the reset button for a few seconds while the system is powered on.\n",
      "\n",
      "4. **Check the Firmware:**\n",
      "   Ensure that the firmware running on the ESP32 board is up-to-date and compatible with your setup. You may need to update or replace the firmware if there are compatibility issues.\n",
      "\n",
      "5. **Debugging:**\n",
      "   Use debugging tools such as an oscilloscope or debugger to monitor the signals being sent from the ESP32 to the LCD display. This will help identify any issues with signal integrity or timing.\n",
      "\n",
      "6. **Update Display Code:**\n",
      "   If you have written custom code for the LCD display, ensure it is correctly implemented and handles unexpected inputs gracefully. It's possible that your code might not handle the case where the system is stopped properly.\n",
      "\n",
      "7. **Inspect the Display Module:**\n",
      "   Check if the LCD display module itself has any physical damage or internal issues causing it to show incorrect information.\n",
      "\n",
      "8. **Check the Ground Connection:**\n",
      "   Ensure that the ground connection is solid and clean. Poor grounding can affect the stability of the LCD display.\n",
      "\n",
      "If after following these steps the issue persists, consider seeking assistance from a professional or someone experienced in hardware troubleshooting."
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T21:34:32.300164Z",
     "start_time": "2024-11-27T21:34:32.296272Z"
    }
   },
   "cell_type": "code",
   "source": "model.__class__",
   "id": "a0d916b2735db9e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers_modules.openbmb.MiniCPM-V-2_6-int4.6f1555d8e2359cb18595da9f1864cb41631e0617.modeling_minicpmv.MiniCPMV"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "hf_model = HuggingFacePipeline()\n"
   ],
   "id": "2125a4b4e0bfc2ac"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
